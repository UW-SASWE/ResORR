import geopandas as gpd
from pathlib import Path
import pandas as pd
import xarray as xr
import numpy as np
import geonetworkx as gnx



# aggregate
def aggregate(ds, frequency='weekly'):
    if frequency == 'daily':
        resampled = ds
        resampled['dt'] = ds['time'].resample(time='1D').count()
    elif frequency == 'weekly':
        resampled = ds.resample(time='1W').mean()
        resampled['dt'] = ds['time'].resample(time='1W').count()
    elif frequency == 'monthly':
        resampled = ds.resample(time='1M').mean()
        resampled['dt'] = ds['time'].resample(time='1M').count()
    elif frequency == 'annual':
        resampled = ds.resample(time='1Y').mean()
        resampled['dt'] = ds['time'].resample(time='1Y').count()
    else:
        raise ValueError(f'frequency {frequency} not supported')
    
    return resampled

def calculate_volumes(
        ds, 
        fluxes=['unregulated_inflow', 'storage_change']
    ):
    """Calculate volume values using flow rates and âˆ†t

    Args:
        ds (xr.Dataset): Dataset containing flow rates in m3/day
        fluxes (list, optional): List of fluxes to calculate volumes for. Defaults to ['unregulated_inflow', 'storage_change'].
    """
    for flux in fluxes:
        ds[flux] = ds[flux] * ds['dt']
        ds[flux].attrs['units'] = 'm3'
        ds[flux].attrs['long_name'] = f'Volume of {flux}'
        ds[flux].attrs['description'] = f'Volume of {flux} in m3'

    return ds

def _rat_read_inflow(unregulated_inflow_fn, resorr_node_id, rat_output_level='final_outputs') -> xr.Dataset:
    """returns inflow files generated by RAT under pristine conditions as unregulated inflow.

    Args:
        unregulated_inflow_fn (str): path of the unregulated inflow file
        rat_output_level (str, optional): whether to read from `final_outputs` or `rat_outputs`, which are slightly different in units and file formatting. Defaults to 'final_outputs'.

    Returns:
        xr.Dataset: unregulated inflow
    """
    if rat_output_level == 'final_outputs':
        unregulated_inflow = pd.read_csv(unregulated_inflow_fn, parse_dates=['date']).rename({
            'date': 'time',
            'inflow (m3/d)': 'unregulated_inflow'
            }, axis='columns')
    elif rat_output_level == 'rat_outputs':
        unregulated_inflow = pd.read_csv(unregulated_inflow_fn, parse_dates=['date']).rename({
            'date': 'time',
            'streamflow': 'unregulated_inflow'
            }, axis='columns')
        unregulated_inflow['unregulated_inflow'] = unregulated_inflow['unregulated_inflow'] * (24*60*60) # m3/s -> m3/day

    unregulated_inflow['node'] = resorr_node_id
    unregulated_inflow.set_index(['time', 'node'], inplace=True)
    unregulated_inflow = unregulated_inflow.to_xarray()

    return unregulated_inflow

def _rat_read_storage_change(storage_change_fn, resorr_node_id):
    storage_change = pd.read_csv(storage_change_fn, parse_dates=['date']).rename({
        'date': 'time',
        'dS (m3)': 'storage_change'
    }, axis='columns')[['time', 'storage_change']]

    # convert storage_change to daily - https://stackoverflow.com/a/73724900
    storage_change = storage_change.set_index('time')
    storage_change = storage_change.resample('1D').apply(lambda x: np.nan if x.empty else x)
    groups = storage_change['storage_change'].notna()[::-1].cumsum()
    storage_change['storage_change'] = storage_change['storage_change'].fillna(0).groupby(groups).transform('mean')
    storage_change['node'] = resorr_node_id
    storage_change = storage_change.reset_index().set_index(['time', 'node'])
    storage_change = storage_change.to_xarray()

    return storage_change

def generate_forcings_from_rat(
        reservoir_network, 
        inflow_dir, 
        storage_change_dir, 
        save_dir, 
        aggregate_freq='daily',
        rat_output_level='final_outputs'
    ):
    """

    Args:
        reservoir_network (gnx.GeoDiGraph or str or pathlib.Path): reservoir network as GeoDiGraph or path to directory containing files generated by generate_network
        inflow_dir (str or Path): path to directory containing inflow files
        storage_change_dir (str or Path): path to directory containing storage change files
        save_dir (str or Path): directory to save regulation data to
    """
    # check if files exist
    inflow_dir = Path(inflow_dir)
    assert inflow_dir.exists()

    storage_change_dir = Path(storage_change_dir)
    assert storage_change_dir.exists()

    save_dir = Path(save_dir)
    if not save_dir.exists():
        print(f"passed save_dir does not exist, creating {save_dir}")
        save_dir.mkdir(parents=True)

    if isinstance(reservoir_network, gnx.GeoDiGraph):
        G = reservoir_network
    elif isinstance(reservoir_network, str) or isinstance(reservoir_network, Path):
        reservoir_network = gpd.read_file(Path(reservoir_network) / 'rivreg_network.shp')
        reservoir_network_pts = gpd.read_file(Path(reservoir_network) / 'rivreg_network_pts.shp')
        print(reservoir_network, reservoir_network_pts)
        G = gnx.read_geofiles(reservoir_network, reservoir_network_pts, directed=True)
    else:
        raise TypeError(f"reservoir_network must be of type gnx.GeoDiGraph or str or pathlib.Path. type of passed reservoir_network - {type(reservoir_network)}")

    datasets_to_join = []
    for node_id in G:
        node = G.nodes[node_id]
        name = node['name']

        # unregulated inflow
        unregulated_inflow_fn = inflow_dir / f"{name}.csv"

        if not unregulated_inflow_fn.exists():
            print(f"Missing {unregulated_inflow_fn}")
            continue
        unregulated_inflow = _rat_read_inflow(
            unregulated_inflow_fn, node_id, rat_output_level=rat_output_level)
        datasets_to_join.append(unregulated_inflow)

        # storage change
        storage_change_fn = storage_change_dir / f"{name}.csv"
        if storage_change_fn.exists():
            storage_change = _rat_read_storage_change(storage_change_fn, node_id)
            datasets_to_join.append(storage_change)

    rat_data = xr.merge(datasets_to_join)

    aggregated_volumes = calculate_volumes(aggregate(rat_data, frequency=aggregate_freq))

    forcings = xr.Dataset(
        data_vars={
            'theoretical_natural_runoff': aggregated_volumes['unregulated_inflow'],
            'storage_change': aggregated_volumes['storage_change'],
            'dt': aggregated_volumes['dt']
        }
    )

    # save regulation data
    forcings.to_netcdf(save_dir / 'resorr_forcings.nc')

    return forcings
